{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from itertools import permutations, combinations, cycle\n",
    "import os \n",
    "from random import sample, shuffle \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import cv2 as cv\n",
    "import sklearn.metrics\n",
    "import re\n",
    "from efficientnet import tfkeras as efn \n",
    "from pathlib import Path\n",
    "import rasterio \n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, EarlyStopping, CSVLogger, TensorBoard, ReduceLROnPlateau\n",
    "import segmentation_models as sm\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import wkt\n",
    "\n",
    "from typing import List, Tuple\n",
    "from slacker import Slacker\n",
    "slack = Slacker('xoxp-406617419703-407736556887-975525827328-1c7c24b94d95408268b84ada0b16d937')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "print(sm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COMMON_PATH = Path('train/AOI_11_Rotterdam')\n",
    "TRAIN_SAR_PATH = TRAIN_COMMON_PATH/'SAR-Intensity'\n",
    "TRAIN_GT_PATH = TRAIN_COMMON_PATH/'train_ground_truth'\n",
    "TEST_SAR_PATH = None #TODO\n",
    "TEST_GT_PATH = None #TODO\n",
    "\n",
    "FILENAME_PATTERN = re.compile('SN6_Train_AOI_11_Rotterdam_SAR-Intensity_(\\d*_\\d*_tile_\\d*).tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_to_display(x, n_channels, normalize=True):\n",
    "    preprocessed = x.copy()\n",
    "    if normalize:\n",
    "        preprocessed = preprocessed/preprocessed.max()\n",
    "    if n_channels > 1:\n",
    "        preprocessed = np.moveaxis(preprocessed[:3], 0, -1)\n",
    "    else: \n",
    "        preprocessed = preprocessed[0]\n",
    "    return preprocessed\n",
    "\n",
    "def get_sar_imagery_statistics(path):\n",
    "    array = get_array_from_tiff(path)\n",
    "    means = array.mean(axis=(1,2))\n",
    "    stds = array.std(axis=(1,2))\n",
    "    return means, stds\n",
    "\n",
    "def get_array_from_tiff(path):\n",
    "    with rasterio.open(path) as file: \n",
    "        im = file.read()\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>TileBuildingId</th>\n",
       "      <th>PolygonWKT_Pix</th>\n",
       "      <th>Mean_Building_Height</th>\n",
       "      <th>Median_Building_Height</th>\n",
       "      <th>StdDev_Building_Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((299.6396801332012 349.3765436094254,...</td>\n",
       "      <td>9.962397</td>\n",
       "      <td>9.96</td>\n",
       "      <td>0.006495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((115.5360228798818 339.845588516444, ...</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((768.9086768317502 329.8960437048227,...</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>14.42</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((755.8174585120287 330.0953964963555,...</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>14.42</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((392.8786215754226 335.6222213506699,...</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214677</th>\n",
       "      <td>20190822133333_20190822133635_tile_7758</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((241.8162563492078 165.4673625379801,...</td>\n",
       "      <td>5.970000</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214678</th>\n",
       "      <td>20190822133333_20190822133635_tile_7758</td>\n",
       "      <td>6</td>\n",
       "      <td>POLYGON ((431.9838383866008 146.2224273793399,...</td>\n",
       "      <td>10.380000</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214679</th>\n",
       "      <td>20190822133333_20190822133635_tile_7758</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((128.6518265847117 111.3799640219659,...</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214680</th>\n",
       "      <td>20190822133333_20190822133635_tile_7758</td>\n",
       "      <td>8</td>\n",
       "      <td>POLYGON ((415.3016002546065 98.69750475697219,...</td>\n",
       "      <td>11.710000</td>\n",
       "      <td>11.71</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214681</th>\n",
       "      <td>20190822133333_20190822133635_tile_7758</td>\n",
       "      <td>9</td>\n",
       "      <td>POLYGON ((835.701504310593 124.1703369021416, ...</td>\n",
       "      <td>6.410000</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214682 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageId  TileBuildingId  \\\n",
       "0       20190822070610_20190822070846_tile_3721               0   \n",
       "1       20190822070610_20190822070846_tile_3721               1   \n",
       "2       20190822070610_20190822070846_tile_3721               2   \n",
       "3       20190822070610_20190822070846_tile_3721               3   \n",
       "4       20190822070610_20190822070846_tile_3721               4   \n",
       "...                                         ...             ...   \n",
       "214677  20190822133333_20190822133635_tile_7758               5   \n",
       "214678  20190822133333_20190822133635_tile_7758               6   \n",
       "214679  20190822133333_20190822133635_tile_7758               7   \n",
       "214680  20190822133333_20190822133635_tile_7758               8   \n",
       "214681  20190822133333_20190822133635_tile_7758               9   \n",
       "\n",
       "                                           PolygonWKT_Pix  \\\n",
       "0       POLYGON ((299.6396801332012 349.3765436094254,...   \n",
       "1       POLYGON ((115.5360228798818 339.845588516444, ...   \n",
       "2       POLYGON ((768.9086768317502 329.8960437048227,...   \n",
       "3       POLYGON ((755.8174585120287 330.0953964963555,...   \n",
       "4       POLYGON ((392.8786215754226 335.6222213506699,...   \n",
       "...                                                   ...   \n",
       "214677  POLYGON ((241.8162563492078 165.4673625379801,...   \n",
       "214678  POLYGON ((431.9838383866008 146.2224273793399,...   \n",
       "214679  POLYGON ((128.6518265847117 111.3799640219659,...   \n",
       "214680  POLYGON ((415.3016002546065 98.69750475697219,...   \n",
       "214681  POLYGON ((835.701504310593 124.1703369021416, ...   \n",
       "\n",
       "        Mean_Building_Height  Median_Building_Height  StdDev_Building_Height  \n",
       "0                   9.962397                    9.96                0.006495  \n",
       "1                   2.810000                    2.81                0.000000  \n",
       "2                  14.420000                   14.42                0.000000  \n",
       "3                  14.420000                   14.42                0.000000  \n",
       "4                   8.590000                    8.59                0.000000  \n",
       "...                      ...                     ...                     ...  \n",
       "214677              5.970000                    5.97                0.000000  \n",
       "214678             10.380000                   10.38                0.000000  \n",
       "214679              3.870000                    3.87                0.000000  \n",
       "214680             11.710000                   11.71                0.000000  \n",
       "214681              6.410000                    6.41                0.000000  \n",
       "\n",
       "[214682 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings = pd.read_csv(TRAIN_COMMON_PATH/'SummaryData/SN6_Train_AOI_11_Rotterdam_Buildings.csv',engine='python')\n",
    "buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_filename(filename):\n",
    "    return FILENAME_PATTERN.match(filename)[1]\n",
    "\n",
    "def get_polygons_in_image(rstr_filename):\n",
    "    image_id = get_id_from_filename(rstr_filename)\n",
    "    return buildings.loc[buildings['ImageId']==image_id,'PolygonWKT_Pix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3401"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(buildings['ImageId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATASET_SIZE=200840\n",
    "#TRAINING_DATASET_SIZE =200\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "\n",
    "\n",
    "\n",
    "class ImageGen:\n",
    "    def __init__(self, mode=\"fit\", shuffle=False, batch_type='full_image', batch_size=32, train_val_frac = 0.8, verbose=False):\n",
    "        \n",
    "        assert not (mode=='test' and shuffle==True), 'Error: in test mode, the values should not be shuffled.'\n",
    "\n",
    "        self.batch_size = batch_size \n",
    "        if mode == \"fit\":\n",
    "            self.image_path = TRAIN_SAR_PATH\n",
    "            self.gt_path = TRAIN_GT_PATH\n",
    "        if mode == \"test\":\n",
    "            self.image_path = TEST_SAR_PATH\n",
    "            self.gt_path = TEST_GT_PATH\n",
    "        \n",
    "        self.generators = {}\n",
    "        self.orientations = pd.read_csv('train/AOI_11_Rotterdam/SummaryData/SAR_orientations.txt',sep=' ', header=None)\n",
    "        self.orientations.columns = [\"image_timestamps\",\"orientation\"]\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        image_files = os.listdir(self.image_path)\n",
    "        if shuffle == True: \n",
    "            shuffle(image_files)\n",
    "        if batch_type == 'full_image':\n",
    "            if mode == 'fit':\n",
    "                n_train = int(train_val_frac*len(image_files))\n",
    "                self.generators[\"train\"] = cycle((x for x in image_files[:n_train]))\n",
    "                self.generators['validation'] = cycle((x for x in image_files[n_train:]))\n",
    "            elif mode == \"test\":\n",
    "                raise ValueError(\"Test mode not implemented yet.\")\n",
    "        elif batch_type == 'multiple_images':\n",
    "            n_train = int(train_val_frac*len(image_files))            \n",
    "            self.generators[\"train\"] = cycle((image_files[i:i+batch_size] for i in range(0, len(image_files[:n_train]), batch_size))) \n",
    "            self.generators['validation'] = cycle((image_files[i:i+batch_size] for i in range(0, len(image_files[:n_train]), batch_size))) \n",
    "            \n",
    "    def print_if_verbose(self, *args, status='always'):\n",
    "        if self.verbose and status=='always':\n",
    "            print(*args)\n",
    "        if self.verbose=='debug' and status=='debug':\n",
    "            print(*args)\n",
    "\n",
    "    def normalize(self,batch,normalization_type=None):\n",
    "        if normalization_type is None:\n",
    "            normalized_batch=batch \n",
    "        elif normalization_type=='divide':\n",
    "            normalized_batch=batch/255\n",
    "        return normalized_batch\n",
    "\n",
    "    def get_x_image(self, im_id):\n",
    "        batch = get_array_from_tiff(self.image_path/im_id)\n",
    "        x_batch = np.ndarray(shape=(4,HEIGHT,WIDTH))\n",
    "        for i in range(4):\n",
    "            x_batch[i] = cv.resize(batch[i],dsize=(WIDTH,HEIGHT))\n",
    "        x_batch = self.normalize(x_batch)\n",
    "        x_batch = np.expand_dims(np.rollaxis(x_batch, 0, 3),axis=0)[...,:3]\n",
    "        return x_batch \n",
    "\n",
    "    def get_y_image(self, im_id):\n",
    "        batch = np.rollaxis(get_array_from_tiff(self.gt_path/im_id)[0], 0, 2)\n",
    "        batch = np.rot90(batch, k=3)\n",
    "        batch = np.flip(batch,axis=1)\n",
    "        batch = cv.resize(batch,dsize=(WIDTH,HEIGHT))\n",
    "        batch = np.uint8(batch > 0)\n",
    "        batch = np.expand_dims(batch,axis=0)\n",
    "        batch = np.expand_dims(batch,axis=-1)\n",
    "        return batch \n",
    "    \n",
    "    #def merge_as_batch(self):\n",
    "        \n",
    "    def flow(self, mode: str =\"train\", height: int =137,width: int =236):\n",
    "        '''Run the generator '''\n",
    "        c = 0\n",
    "        while True:\n",
    "            image_ids_to_get = next(self.generators[mode])\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            for im_id in image_ids_to_get:\n",
    "                image_orientation = self.orientations.loc[self.orientations[\"image_timestamps\"]==re.match('.*(\\d{14}_\\d{14})',im_id)[1],\"orientation\"]\n",
    "                self.print_if_verbose(\"\\n INFO - image_ids_to_get:\", im_id,\"\\n\",status='always')\n",
    "                self.print_if_verbose(\"\\n INFO - image_orientation:\",image_orientation)\n",
    "                x_image = self.get_x_image(im_id)\n",
    "                x_batch.append(x_image)\n",
    "                if mode in ('train','validation'):\n",
    "                    self.print_if_verbose(\"\\n INFO - current mode \",mode,status=\"debug\")\n",
    "                    y_image = self.get_y_image(im_id)\n",
    "                    y_batch.append(y_image)\n",
    "            x_batch = np.concatenate(x_batch)\n",
    "            y_batch = np.concatenate(y_batch)\n",
    "            if mode in ('train','validation'):\n",
    "                yield x_batch, y_batch\n",
    "            elif mode=='test':\n",
    "                c+=1\n",
    "                print(f\"\\n INFO - Yielding test data nÂ°{c}/{self.batch_size/self.files_size['test']}\")\n",
    "                yield x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = sm.Unet()\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[sm.metrics.iou_score],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FRAC = 0.8\n",
    "N_TRAIN = 3401\n",
    "BATCH_SIZE = 32\n",
    "STEP_PER_EPOCH = int(TRAIN_FRAC*N_TRAIN)//BATCH_SIZE+1\n",
    "VAL_STEPS_PER_EPOCH = int((1-TRAIN_FRAC)*N_TRAIN)//BATCH_SIZE+1\n",
    "N_EPOCHS = 40\n",
    "LOG_DIR = 'logs/'\n",
    "MODELS_DIR = \"models/\"\n",
    "LOAD_MODEL = True\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    STEP_PER_EPOCH= 10\n",
    "    VAL_STEPS_PER_EPOCH= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_generator = ImageGen(verbose=False, batch_type=\"multiple_images\", batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(fit_generator.flow(mode='validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 256, 256, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 31211368\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 16:58 model_weights-06-0.2983--0.2848.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 16:37 model_weights-05-0.2993--0.2814.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 16:18 model_weights-04-0.2914--0.2852.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 16:00 model_weights-03-0.2880--0.2829.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 15:42 model_weights-02-0.2782--0.2860.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 15:24 model_weights-01-0.2771--0.2840.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 13:42 model_weights-06-0.3033--0.2724.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 13:23 model_weights-05-0.3020--0.2683.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 13:05 model_weights-04-0.2942--0.2714.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 12:48 model_weights-03-0.2916--0.2681.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 12:30 model_weights-02-0.2824--0.2718.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 12:12 model_weights-01-0.2717--0.2718.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 09:27 model_weights-06-0.2725--0.2650.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 09:09 model_weights-05-0.2580--0.2648.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 08:50 model_weights-04-0.2499--0.2739.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 08:33 model_weights-03-0.2433--0.2721.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 08:15 model_weights-02-0.2436--0.2623.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 07:58 model_weights-01-0.2308--0.2573.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 00:52 model_weights-11-0.2314--0.2503.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 00:35 model_weights-10-0.2124--0.2505.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 10 00:16 model_weights-09-0.2271--0.2099.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 23:58 model_weights-08-0.1957--0.2429.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 23:41 model_weights-07-0.1784--0.2700.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 23:23 model_weights-06-0.1432--0.2814.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 23:06 model_weights-05-0.1878--0.2298.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 22:48 model_weights-04-0.2022--0.2387.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 22:31 model_weights-03-0.1969--0.2489.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 22:13 model_weights-02-0.2172--0.2028.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 21:53 model_weights-01-0.2374--0.2170.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 08:52 model_weights-15-0.1981.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 08:02 model_weights-14-0.1975.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 07:12 model_weights-13-0.2059.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 06:22 model_weights-12-0.1965.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 05:30 model_weights-11-0.1909.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 04:41 model_weights-10-0.1619.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 03:49 model_weights-09-0.1983.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 03:00 model_weights-08-0.1816.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 02:10 model_weights-07-0.1694.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 01:21 model_weights-06-0.2058.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  9 00:32 model_weights-05-0.1994.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 23:42 model_weights-04-0.2044.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 22:53 model_weights-03-0.1866.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 22:03 model_weights-02-0.1939.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 21:14 model_weights-01-0.2091.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 20:07 model_weights-02-0.2221.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 19:43 model_weights-01-0.1455.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 18:42 model_weights-05-0.1714.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 17:36 model_weights-04-0.1749.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 16:39 model_weights-03-0.1743.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 15:48 model_weights-02-0.1771.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 14:57 model_weights-01-0.2154.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 11:27 model_weights-15-0.1746.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 11:09 model_weights-14-0.1672.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 10:50 model_weights-13-0.1644.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 10:32 model_weights-12-0.1729.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 10:14 model_weights-11-0.1721.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 09:55 model_weights-10-0.1504.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 09:37 model_weights-09-0.1687.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 09:19 model_weights-08-0.1812.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 08:57 model_weights-07-0.1527.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 08:30 model_weights-06-0.1801.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 08:09 model_weights-05-0.1644.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 07:52 model_weights-04-0.1896.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 07:31 model_weights-03-0.1901.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 07:12 model_weights-02-0.1638.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  8 06:55 model_weights-01-0.1892.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 22:38 model_weights-10-0.1722.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 22:21 model_weights-09-0.1678.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 21:58 model_weights-08-0.1809.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 21:40 model_weights-07-0.1828.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 21:22 model_weights-06-0.1903.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 21:05 model_weights-05-0.1455.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 20:48 model_weights-04-0.2340.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 20:29 model_weights-03-0.1921.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 20:11 model_weights-02-0.1918.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 19:54 model_weights-01-0.2022.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 18:43 model_weights-11-0.1680.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 18:25 model_weights-10-0.1958.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 18:06 model_weights-09-0.2100.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 17:49 model_weights-08-0.1855.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 17:32 model_weights-07-0.2041.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 17:14 model_weights-06-0.1620.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 16:57 model_weights-05-0.2107.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 16:39 model_weights-04-0.1897.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 16:22 model_weights-03-0.1860.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 16:03 model_weights-02-0.2045.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 15:46 model_weights-01-0.2014.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 14:49 model_weights-15-0.1716.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 14:30 model_weights-14-0.1781.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 14:13 model_weights-13-0.1609.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 13:56 model_weights-12-0.1957.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 13:38 model_weights-11-0.2083.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 13:21 model_weights-10-0.1607.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 13:03 model_weights-09-0.1802.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 12:44 model_weights-08-0.1698.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 12:27 model_weights-07-0.1655.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 12:09 model_weights-06-0.1721.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 11:51 model_weights-05-0.1722.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 11:33 model_weights-04-0.1691.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 11:15 model_weights-03-0.1786.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 10:58 model_weights-02-0.1778.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 10:40 model_weights-01-0.1855.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 09:54 model_weights-02-0.2303.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 09:05 model_weights-01-0.2241.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr  7 08:00 model_weights-01-0.2019.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr  7 07:04 model_weights-01-0.2072.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr  7 06:42 model_weights-06-0.2284.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr  7 06:24 model_weights-05-0.2306.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr  7 06:06 model_weights-04-0.2098.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr  7 05:48 model_weights-03-0.2011.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr  7 05:30 model_weights-02-0.1980.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr  7 05:13 model_weights-01-0.1977.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lt models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, EarlyStopping, CSVLogger, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(MODELS_DIR+\"model_weights-{epoch:02d}-{val_loss:.4f}--{val_iou_score:.4f}.hdf5\", \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=False, \n",
    "                             mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              verbose=0, mode='auto')\n",
    "csv_logger = CSVLogger(LOG_DIR+'training.log')\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    model.load_weights(f'{MODELS_DIR}/model_weights-15-0.1981.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-8c52732d83cf>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 86 steps, validate for 22 steps\n",
      "Epoch 1/40\n",
      "86/86 [==============================] - 1063s 12s/step - loss: 0.0600 - iou_score: 0.6202 - val_loss: 0.0695 - val_iou_score: 0.5717\n",
      "Epoch 2/40\n",
      "86/86 [==============================] - 1028s 12s/step - loss: 0.0498 - iou_score: 0.6590 - val_loss: 0.0512 - val_iou_score: 0.6480\n",
      "Epoch 3/40\n",
      "86/86 [==============================] - 1223s 14s/step - loss: 0.0464 - iou_score: 0.6791 - val_loss: 0.0448 - val_iou_score: 0.6729\n",
      "Epoch 4/40\n",
      "86/86 [==============================] - 1202s 14s/step - loss: 0.0442 - iou_score: 0.6918 - val_loss: 0.0481 - val_iou_score: 0.6730\n",
      "Epoch 5/40\n",
      "86/86 [==============================] - 935s 11s/step - loss: 0.0428 - iou_score: 0.7019 - val_loss: 0.0387 - val_iou_score: 0.7154\n",
      "Epoch 6/40\n",
      "86/86 [==============================] - 978s 11s/step - loss: 0.0411 - iou_score: 0.7106 - val_loss: 0.0423 - val_iou_score: 0.7050\n",
      "Epoch 7/40\n",
      "86/86 [==============================] - 1169s 14s/step - loss: 0.0401 - iou_score: 0.7170 - val_loss: 0.0448 - val_iou_score: 0.6990\n",
      "Epoch 8/40\n",
      "86/86 [==============================] - 1426s 17s/step - loss: 0.0392 - iou_score: 0.7220 - val_loss: 0.0385 - val_iou_score: 0.7270\n",
      "Epoch 9/40\n",
      "86/86 [==============================] - 986s 11s/step - loss: 0.0388 - iou_score: 0.7239 - val_loss: 0.0438 - val_iou_score: 0.7166\n",
      "Epoch 10/40\n",
      "86/86 [==============================] - 1150s 13s/step - loss: 0.0391 - iou_score: 0.7236 - val_loss: 0.0448 - val_iou_score: 0.7139\n",
      "Epoch 11/40\n",
      "86/86 [==============================] - 1275s 15s/step - loss: 0.0393 - iou_score: 0.7230 - val_loss: 0.0412 - val_iou_score: 0.7177\n",
      "Epoch 12/40\n",
      "86/86 [==============================] - 1037s 12s/step - loss: 0.0402 - iou_score: 0.7171 - val_loss: 0.0448 - val_iou_score: 0.7103\n",
      "Epoch 13/40\n",
      "14/86 [===>..........................] - ETA: 4:08 - loss: 0.0405 - iou_score: 0.7119"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " fit mo\n",
    "model.fit_generator(\n",
    "   fit_generator.flow(mode='train'),\n",
    "   epochs=N_EPOCHS,\n",
    "   steps_per_epoch=STEP_PER_EPOCH,\n",
    "   validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "   validation_data=fit_generator.flow(mode='validation'),\n",
    "   callbacks = [\n",
    "                #checkpoint, \n",
    "                #early_stopping, \n",
    "                #csv_logger, \n",
    "                #reduce_lr_on_plateau\n",
    "                ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_log(x):\n",
    "    y = x.copy()\n",
    "    y[y==0]=1\n",
    "    return 10*np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = next(fit_generator.flow(mode='validation'))\n",
    "\n",
    "fig, ax = plt.subplots(2,3, figsize=(15,9))\n",
    "pred = model.predict(img[0])\n",
    "ax = ax.ravel()\n",
    "for i in range(3):\n",
    "    ax[i].imshow(img[0][0,...,i],cmap='gist_gray',vmin=15,vmax=60)\n",
    "    ax[3+i].imshow(safe_log(img[0][0,...,i]),cmap='gist_gray',vmin=11,vmax=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(fit_generator.flow(mode='validation'))\n",
    "\n",
    "fig, ax = plt.subplots(2,3, figsize=(20,20))\n",
    "pred = model.predict(img[0])\n",
    "for i in range(3):\n",
    "    ax[0,i].imshow(img[0][0,...,i],cmap='gist_gray',vmin=25,vmax=60)\n",
    "\n",
    "ax[1,0].imshow(pred[0,...,0],cmap='gist_gray')\n",
    "ax[1,1].imshow(img[1][0,...,0],cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(fit_generator.flow(mode='validation'))\n",
    "fig, ax = plt.subplots(2,1, figsize=(30,30))\n",
    "ax[0].imshow(img[0][0,...,0],cmap='gist_gray',vmin=10,vmax=60)\n",
    "ax[1].imshow(img[1][0,...,0],cmap='Oranges',alpha=1)\n",
    "ax[1].imshow(safe_log(img[0][0,...,0]),cmap='Blues_r',alpha=0.8, vmin=12, vmax=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.rot90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img[1][0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[1][0,...] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0][0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[1][0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[1][0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = Input(shape=(900,900,4))\n",
    "first_layer = Conv2D(3,(3,3))(new_input)\n",
    "other_layers= model.get_layer(\"block1_conv1\")(first_layer)\n",
    "\n",
    "#Model(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers.pop(0)\n",
    "model.layers\n",
    "\n",
    "newInput = Input(batch_shape=(4,900,900,1))\n",
    "newOutputs = model\n",
    "newModel = Model(newInput, newOutputs)\n",
    "\n",
    "newModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('/Users/a955nd/Programming/axa_climate/managing_provider/data-provider-docs/fastcat_validate_da/tests/data/integration/test_gsi_jackson_26022020_with_satellite_images/raw_bucket/92e5c126-e9d0-423a-95b6-f5284a8e22c8_satellite_raw_iceye_1581871651_0_v0.tiff') as f: \n",
    "    a=f.read()\n",
    "    b=f.meta\n",
    "    with rasterio.open('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
