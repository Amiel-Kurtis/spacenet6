{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "2.1.0\n",
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "#TODO: Ajouter descartes\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from itertools import permutations, combinations, cycle\n",
    "import os \n",
    "from random import sample, shuffle \n",
    "import gc \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import cv2 as cv\n",
    "import sklearn.metrics\n",
    "import re\n",
    "from pathlib import Path\n",
    "import rasterio \n",
    "from rasterio import features\n",
    "import geopandas as gpd\n",
    "from affine import Affine\n",
    "from rasterstats import gen_zonal_stats\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, EarlyStopping, CSVLogger, TensorBoard, ReduceLROnPlateau\n",
    "import tensorflow as tf \n",
    "from efficientnet import tfkeras as efn \n",
    "import segmentation_models as sm\n",
    "from rasterstats import zonal_stats\n",
    "print(tf.__version__)\n",
    "print(sm.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import wkt\n",
    "\n",
    "from typing import List, Tuple\n",
    "from slacker import Slacker\n",
    "slack = Slacker('xoxp-406617419703-407736556887-975525827328-1c7c24b94d95408268b84ada0b16d937')\n",
    "\n",
    "from system import sizeof_fmt, get_resources_usage\n",
    "from helpers import preprocess_to_display, get_sar_imagery_statistics, get_array_from_tiff, get_id_from_filename, get_polygons_in_image\n",
    "\n",
    "TRAIN_COMMON_PATH = Path('train/AOI_11_Rotterdam')\n",
    "TEST_COMMON_PATH = Path('test_public/AOI_11_Rotterdam')\n",
    "TRAIN_SAR_PATH = TRAIN_COMMON_PATH/'SAR-Intensity'\n",
    "TRAIN_GT_PATH = TRAIN_COMMON_PATH/'train_ground_truth'\n",
    "TEST_SAR_PATH = TEST_COMMON_PATH/'SAR-Intensity'\n",
    "\n",
    "FILENAME_PATTERN = {}\n",
    "FILENAME_PATTERN['train'] = re.compile('SN6_Train_AOI_11_Rotterdam_SAR-Intensity_(\\d*_\\d*_tile_\\d*).tif')\n",
    "FILENAME_PATTERN['validation'] = re.compile('SN6_Train_AOI_11_Rotterdam_SAR-Intensity_(\\d*_\\d*_tile_\\d*).tif')\n",
    "FILENAME_PATTERN['test'] = re.compile('SN6_Test_Public_AOI_11_Rotterdam_SAR-Intensity_(\\d*_\\d*_tile_\\d*).tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28G\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 20:59 model_weights--efficientnetb3-11-0.1135--0.5224.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 20:37 model_weights--efficientnetb3-10-0.1115--0.5304.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 20:14 model_weights--efficientnetb3-09-0.1250--0.5238.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 19:52 model_weights--efficientnetb3-08-0.1148--0.5307.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 19:30 model_weights--efficientnetb3-07-0.1115--0.5312.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 19:08 model_weights--efficientnetb3-06-0.1117--0.5272.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 18:45 model_weights--efficientnetb3-05-0.1196--0.5024.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 18:21 model_weights--efficientnetb3-04-0.1152--0.5321.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 18:00 model_weights--efficientnetb3-03-0.1140--0.5263.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 17:38 model_weights--efficientnetb3-02-0.1134--0.5333.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 17:17 model_weights--efficientnetb3-01-0.1198--0.5345.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 15:54 model_weights--efficientnetb3-22-0.1167--0.5421.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 15:30 model_weights--efficientnetb3-21-0.1158--0.5424.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 15:10 model_weights--efficientnetb3-20-0.1154--0.5417.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 14:48 model_weights--efficientnetb3-19-0.1137--0.5418.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 14:25 model_weights--efficientnetb3-18-0.1133--0.5416.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 14:00 model_weights--efficientnetb3-17-0.1130--0.5403.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 13:39 model_weights--efficientnetb3-16-0.1121--0.5400.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 13:18 model_weights--efficientnetb3-15-0.1113--0.5394.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 12:56 model_weights--efficientnetb3-14-0.1102--0.5354.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 12:35 model_weights--efficientnetb3-13-0.1084--0.5358.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 12:06 model_weights--efficientnetb3-12-0.1070--0.5322.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 11:44 model_weights--efficientnetb3-11-0.1044--0.5291.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 11:23 model_weights--efficientnetb3-10-0.1023--0.5261.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 11:01 model_weights--efficientnetb3-09-0.1120--0.5190.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 10:37 model_weights--efficientnetb3-08-0.1128--0.5182.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 10:16 model_weights--efficientnetb3-07-0.1111--0.5038.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 09:54 model_weights--efficientnetb3-06-0.1135--0.5028.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 09:32 model_weights--efficientnetb3-05-0.1112--0.5062.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 09:10 model_weights--efficientnetb3-04-0.1116--0.5167.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 08:49 model_weights--efficientnetb3-03-0.1158--0.5102.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 08:27 model_weights--efficientnetb3-02-0.1120--0.5081.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 08:05 model_weights--efficientnetb3-01-0.1188--0.5190.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 01:05 model_weights--efficientnetb3-08-0.1034--0.5219.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 00:41 model_weights--efficientnetb3-07-0.1017--0.5192.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 28 00:16 model_weights--efficientnetb3-06-0.1134--0.5216.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 23:49 model_weights--efficientnetb3-05-0.1069--0.5264.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 23:15 model_weights--efficientnetb3-04-0.1180--0.4991.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 22:46 model_weights--efficientnetb3-03-0.1216--0.4848.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 22:18 model_weights--efficientnetb3-02-0.1061--0.5104.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 21:44 model_weights--efficientnetb3-01-0.1127--0.5267.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 19:53 model_weights--efficientnetb3-17-0.1088--0.5251.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 19:31 model_weights--efficientnetb3-16-0.1078--0.5247.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 19:09 model_weights--efficientnetb3-15-0.1073--0.5236.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 18:44 model_weights--efficientnetb3-14-0.1069--0.5236.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 18:22 model_weights--efficientnetb3-13-0.1054--0.5231.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 17:57 model_weights--efficientnetb3-12-0.1050--0.5221.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 17:34 model_weights--efficientnetb3-11-0.1042--0.5213.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 17:12 model_weights--efficientnetb3-10-0.1039--0.5154.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 16:50 model_weights--efficientnetb3-09-0.1023--0.5130.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 16:29 model_weights--efficientnetb3-08-0.1004--0.5099.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 16:06 model_weights--efficientnetb3-07-0.0980--0.5019.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 15:44 model_weights--efficientnetb3-06-0.1108--0.5058.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 15:22 model_weights--efficientnetb3-05-0.1101--0.4844.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 15:00 model_weights--efficientnetb3-04-0.1088--0.4773.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 14:38 model_weights--efficientnetb3-03-0.1054--0.4956.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 14:17 model_weights--efficientnetb3-02-0.1134--0.4795.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 27 13:55 model_weights--efficientnetb3-01-0.1084--0.4956.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 20:28 model_weights--efficientnetb3-07-0.0638--0.5923.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 20:07 model_weights--efficientnetb3-06-0.0651--0.5915.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 19:44 model_weights--efficientnetb3-05-0.0595--0.6148.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 19:22 model_weights--efficientnetb3-04-0.0662--0.5722.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 19:01 model_weights--efficientnetb3-03-0.0629--0.5843.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 18:39 model_weights--efficientnetb3-02-0.0633--0.5986.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 18:16 model_weights--efficientnetb3-01-0.0669--0.5984.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 17:38 model_weights--efficientnetb3-03-0.0598--0.6612.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 17:38 model_weights--efficientnetb3-02-0.0657--0.6280.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 17:37 model_weights--efficientnetb3-01-0.0880--0.5940.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 14:36 model_weights-21-0.0590--0.6171.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 14:17 model_weights-20-0.0619--0.6100.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 13:57 model_weights-19-0.0545--0.6277.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 13:34 model_weights-18-0.0603--0.6031.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 13:13 model_weights-17-0.0602--0.6069.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 12:45 model_weights-16-0.0536--0.6266.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 12:18 model_weights-15-0.0622--0.5915.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 11:54 model_weights-14-0.0589--0.5990.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 11:31 model_weights-13-0.0584--0.6104.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 11:06 model_weights-12-0.0646--0.5880.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 10:46 model_weights-11-0.0596--0.5952.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 10:22 model_weights-10-0.0654--0.5717.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 10:03 model_weights-09-0.0701--0.5594.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 09:45 model_weights-08-0.0833--0.5371.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 09:23 model_weights-07-0.0773--0.5433.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 09:00 model_weights-06-0.0767--0.5570.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 08:34 model_weights-05-0.0699--0.5551.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 08:12 model_weights-04-0.0809--0.5080.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 07:51 model_weights-03-0.0768--0.5089.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 07:29 model_weights-02-0.0772--0.5333.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 07:03 model_weights-01-0.0857--0.4961.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 06:07 model_weights-20-0.0892--0.4897.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 05:43 model_weights-19-0.0785--0.4960.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 05:22 model_weights-18-0.0876--0.4756.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 05:02 model_weights-17-0.0892--0.4716.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 04:39 model_weights-16-0.0884--0.4694.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 04:12 model_weights-15-0.0983--0.4405.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 03:51 model_weights-14-0.0917--0.4539.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 03:30 model_weights-13-0.0926--0.4599.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 03:09 model_weights-12-0.1017--0.4415.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 02:50 model_weights-11-0.1017--0.4298.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 02:29 model_weights-10-0.1077--0.3896.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 02:10 model_weights-09-0.1152--0.3708.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 01:53 model_weights-08-0.1118--0.3681.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 01:30 model_weights-07-0.1213--0.3418.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 01:09 model_weights-06-0.1251--0.3355.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 00:45 model_weights-05-0.1281--0.3141.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 26 00:21 model_weights-04-0.1470--0.2439.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 23:59 model_weights-03-0.1493--0.2220.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 23:36 model_weights-02-0.2041--0.2033.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 23:13 model_weights-01-0.4051--0.1121.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:31 model_weights-07-6.0030--0.0770.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:30 model_weights-06-5.9981--0.0576.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:30 model_weights-05-5.1046--0.0711.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:29 model_weights-04-8.3805--0.1000.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:29 model_weights-03-9.6803--0.0647.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:28 model_weights-02-3.7228--0.0196.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:27 model_weights-01-7.6915--0.0030.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:26 model_weights-06-38.7753--0.0754.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:25 model_weights-05-71.8457--0.0873.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:25 model_weights-04-135.8607--0.0705.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:25 model_weights-03-56.5476--0.0857.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:24 model_weights-02-32.3509--0.0864.hdf5\r\n",
      "-rw-r--r-- 1 root root 206M Apr 25 22:24 model_weights-01-29.2790--0.0948.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 23 12:11 model_weights-08-0.0629--0.5853.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 23 11:52 model_weights-07-0.0625--0.5936.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 23 11:37 model_weights-06-0.0621--0.5920.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 23 11:17 model_weights-05-0.0675--0.5583.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 23 11:00 model_weights-04-0.0728--0.5563.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 23 10:43 model_weights-03-0.0604--0.5906.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 23 10:24 model_weights-02-0.0674--0.5672.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 23 10:05 model_weights-01-0.0700--0.5894.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 22 16:51 model_weights-05-0.0845--0.4962.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 22 16:33 model_weights-04-0.0800--0.5146.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 22 16:15 model_weights-03-0.0821--0.5089.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 22 15:55 model_weights-02-0.0768--0.5158.hdf5\r\n",
      "-rw-r--r-- 1 root root 273M Apr 22 15:35 model_weights-01-0.0833--0.4978.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lth models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add geopandas & rasterstats to the docker\n",
    "#TODO: add usages in a callback for the fit step\n",
    "#TODO: Learn the \"RGB colors\" and then add it to the second fit, with prediction \n",
    "#TODO: Flip data so that everything has the same orientation vis-à-vis the satellite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>TileBuildingId</th>\n",
       "      <th>PolygonWKT_Pix</th>\n",
       "      <th>Mean_Building_Height</th>\n",
       "      <th>Median_Building_Height</th>\n",
       "      <th>StdDev_Building_Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((299.6396801332012 349.3765436094254,...</td>\n",
       "      <td>9.962397</td>\n",
       "      <td>9.96</td>\n",
       "      <td>0.006495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((115.5360228798818 339.845588516444, ...</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((768.9086768317502 329.8960437048227,...</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>14.42</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((755.8174585120287 330.0953964963555,...</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>14.42</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190822070610_20190822070846_tile_3721</td>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((392.8786215754226 335.6222213506699,...</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ImageId  TileBuildingId  \\\n",
       "0  20190822070610_20190822070846_tile_3721               0   \n",
       "1  20190822070610_20190822070846_tile_3721               1   \n",
       "2  20190822070610_20190822070846_tile_3721               2   \n",
       "3  20190822070610_20190822070846_tile_3721               3   \n",
       "4  20190822070610_20190822070846_tile_3721               4   \n",
       "\n",
       "                                      PolygonWKT_Pix  Mean_Building_Height  \\\n",
       "0  POLYGON ((299.6396801332012 349.3765436094254,...              9.962397   \n",
       "1  POLYGON ((115.5360228798818 339.845588516444, ...              2.810000   \n",
       "2  POLYGON ((768.9086768317502 329.8960437048227,...             14.420000   \n",
       "3  POLYGON ((755.8174585120287 330.0953964963555,...             14.420000   \n",
       "4  POLYGON ((392.8786215754226 335.6222213506699,...              8.590000   \n",
       "\n",
       "   Median_Building_Height  StdDev_Building_Height  \n",
       "0                    9.96                0.006495  \n",
       "1                    2.81                0.000000  \n",
       "2                   14.42                0.000000  \n",
       "3                   14.42                0.000000  \n",
       "4                    8.59                0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings = pd.read_csv(TRAIN_COMMON_PATH/'SummaryData/SN6_Train_AOI_11_Rotterdam_Buildings.csv',engine='python')\n",
    "buildings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FRAC = 0.8\n",
    "N_FIT_DATA = 3401\n",
    "N_TRAIN = int(N_FIT_DATA*0.85)\n",
    "N_VALIDATION = N_FIT_DATA-N_TRAIN\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "STEPS_PER_EPOCH = {}\n",
    "STEPS_PER_EPOCH['test'] = len(os.listdir('test_public/AOI_11_Rotterdam/SAR-Intensity'))//BATCH_SIZE+1\n",
    "STEPS_PER_EPOCH['train'] = N_TRAIN//BATCH_SIZE+1\n",
    "STEPS_PER_EPOCH['validation'] = N_VALIDATION//BATCH_SIZE+1\n",
    "\n",
    "N_EPOCHS = 40\n",
    "LOG_DIR = 'logs/'\n",
    "MODELS_DIR = \"models/\"\n",
    "LOAD_MODEL = True\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 27001196\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 15:54 model_weights--efficientnetb3-22-0.1167--0.5421.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 15:30 model_weights--efficientnetb3-21-0.1158--0.5424.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 15:10 model_weights--efficientnetb3-20-0.1154--0.5417.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 14:48 model_weights--efficientnetb3-19-0.1137--0.5418.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 14:25 model_weights--efficientnetb3-18-0.1133--0.5416.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 14:00 model_weights--efficientnetb3-17-0.1130--0.5403.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 13:39 model_weights--efficientnetb3-16-0.1121--0.5400.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 13:18 model_weights--efficientnetb3-15-0.1113--0.5394.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 12:56 model_weights--efficientnetb3-14-0.1102--0.5354.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 12:35 model_weights--efficientnetb3-13-0.1084--0.5358.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 12:06 model_weights--efficientnetb3-12-0.1070--0.5322.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 11:44 model_weights--efficientnetb3-11-0.1044--0.5291.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 11:23 model_weights--efficientnetb3-10-0.1023--0.5261.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 11:01 model_weights--efficientnetb3-09-0.1120--0.5190.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 10:37 model_weights--efficientnetb3-08-0.1128--0.5182.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 10:16 model_weights--efficientnetb3-07-0.1111--0.5038.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 09:54 model_weights--efficientnetb3-06-0.1135--0.5028.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 09:32 model_weights--efficientnetb3-05-0.1112--0.5062.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 09:10 model_weights--efficientnetb3-04-0.1116--0.5167.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 08:49 model_weights--efficientnetb3-03-0.1158--0.5102.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 08:27 model_weights--efficientnetb3-02-0.1120--0.5081.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 08:05 model_weights--efficientnetb3-01-0.1188--0.5190.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 28 01:05 model_weights--efficientnetb3-08-0.1034--0.5219.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 28 00:41 model_weights--efficientnetb3-07-0.1017--0.5192.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 28 00:16 model_weights--efficientnetb3-06-0.1134--0.5216.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 23:49 model_weights--efficientnetb3-05-0.1069--0.5264.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 23:15 model_weights--efficientnetb3-04-0.1180--0.4991.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 22:46 model_weights--efficientnetb3-03-0.1216--0.4848.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 22:18 model_weights--efficientnetb3-02-0.1061--0.5104.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 21:44 model_weights--efficientnetb3-01-0.1127--0.5267.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 19:53 model_weights--efficientnetb3-17-0.1088--0.5251.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 19:31 model_weights--efficientnetb3-16-0.1078--0.5247.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 19:09 model_weights--efficientnetb3-15-0.1073--0.5236.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 18:44 model_weights--efficientnetb3-14-0.1069--0.5236.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 18:22 model_weights--efficientnetb3-13-0.1054--0.5231.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 17:57 model_weights--efficientnetb3-12-0.1050--0.5221.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 17:34 model_weights--efficientnetb3-11-0.1042--0.5213.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 17:12 model_weights--efficientnetb3-10-0.1039--0.5154.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 16:50 model_weights--efficientnetb3-09-0.1023--0.5130.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 16:29 model_weights--efficientnetb3-08-0.1004--0.5099.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 16:06 model_weights--efficientnetb3-07-0.0980--0.5019.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 15:44 model_weights--efficientnetb3-06-0.1108--0.5058.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 15:22 model_weights--efficientnetb3-05-0.1101--0.4844.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 15:00 model_weights--efficientnetb3-04-0.1088--0.4773.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 14:38 model_weights--efficientnetb3-03-0.1054--0.4956.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 14:17 model_weights--efficientnetb3-02-0.1134--0.4795.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 13:55 model_weights--efficientnetb3-01-0.1084--0.4956.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 20:28 model_weights--efficientnetb3-07-0.0638--0.5923.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 20:07 model_weights--efficientnetb3-06-0.0651--0.5915.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 19:44 model_weights--efficientnetb3-05-0.0595--0.6148.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 19:22 model_weights--efficientnetb3-04-0.0662--0.5722.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 19:01 model_weights--efficientnetb3-03-0.0629--0.5843.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 18:39 model_weights--efficientnetb3-02-0.0633--0.5986.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 18:16 model_weights--efficientnetb3-01-0.0669--0.5984.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 17:38 model_weights--efficientnetb3-03-0.0598--0.6612.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 17:38 model_weights--efficientnetb3-02-0.0657--0.6280.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 17:37 model_weights--efficientnetb3-01-0.0880--0.5940.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 14:36 model_weights-21-0.0590--0.6171.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 14:17 model_weights-20-0.0619--0.6100.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 13:57 model_weights-19-0.0545--0.6277.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 13:34 model_weights-18-0.0603--0.6031.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 13:13 model_weights-17-0.0602--0.6069.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 12:45 model_weights-16-0.0536--0.6266.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 12:18 model_weights-15-0.0622--0.5915.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 11:54 model_weights-14-0.0589--0.5990.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 11:31 model_weights-13-0.0584--0.6104.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 11:06 model_weights-12-0.0646--0.5880.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 10:46 model_weights-11-0.0596--0.5952.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 10:22 model_weights-10-0.0654--0.5717.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 10:03 model_weights-09-0.0701--0.5594.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 09:45 model_weights-08-0.0833--0.5371.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 09:23 model_weights-07-0.0773--0.5433.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 09:00 model_weights-06-0.0767--0.5570.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 08:34 model_weights-05-0.0699--0.5551.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 08:12 model_weights-04-0.0809--0.5080.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 07:51 model_weights-03-0.0768--0.5089.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 07:29 model_weights-02-0.0772--0.5333.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 07:03 model_weights-01-0.0857--0.4961.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 06:07 model_weights-20-0.0892--0.4897.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 05:43 model_weights-19-0.0785--0.4960.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 05:22 model_weights-18-0.0876--0.4756.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 05:02 model_weights-17-0.0892--0.4716.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 04:39 model_weights-16-0.0884--0.4694.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 04:12 model_weights-15-0.0983--0.4405.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 03:51 model_weights-14-0.0917--0.4539.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 03:30 model_weights-13-0.0926--0.4599.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 03:09 model_weights-12-0.1017--0.4415.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 02:50 model_weights-11-0.1017--0.4298.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 02:29 model_weights-10-0.1077--0.3896.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 02:10 model_weights-09-0.1152--0.3708.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 01:53 model_weights-08-0.1118--0.3681.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 01:30 model_weights-07-0.1213--0.3418.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 01:09 model_weights-06-0.1251--0.3355.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 00:45 model_weights-05-0.1281--0.3141.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 00:21 model_weights-04-0.1470--0.2439.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 25 23:59 model_weights-03-0.1493--0.2220.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 25 23:36 model_weights-02-0.2041--0.2033.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 25 23:13 model_weights-01-0.4051--0.1121.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:31 model_weights-07-6.0030--0.0770.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:30 model_weights-06-5.9981--0.0576.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:30 model_weights-05-5.1046--0.0711.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:29 model_weights-04-8.3805--0.1000.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:29 model_weights-03-9.6803--0.0647.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:28 model_weights-02-3.7228--0.0196.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:27 model_weights-01-7.6915--0.0030.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:26 model_weights-06-38.7753--0.0754.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:25 model_weights-05-71.8457--0.0873.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:25 model_weights-04-135.8607--0.0705.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:25 model_weights-03-56.5476--0.0857.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:24 model_weights-02-32.3509--0.0864.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:24 model_weights-01-29.2790--0.0948.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 12:11 model_weights-08-0.0629--0.5853.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 11:52 model_weights-07-0.0625--0.5936.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 11:37 model_weights-06-0.0621--0.5920.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 11:17 model_weights-05-0.0675--0.5583.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 11:00 model_weights-04-0.0728--0.5563.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 10:43 model_weights-03-0.0604--0.5906.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 10:24 model_weights-02-0.0674--0.5672.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 10:05 model_weights-01-0.0700--0.5894.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 16:51 model_weights-05-0.0845--0.4962.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 16:33 model_weights-04-0.0800--0.5146.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 16:15 model_weights-03-0.0821--0.5089.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 15:55 model_weights-02-0.0768--0.5158.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 15:35 model_weights-01-0.0833--0.4978.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "ls -lt models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2720"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_frac=0.8\n",
    "batch_size = 32\n",
    "n_data_train = int(train_val_frac*N_FIT_DATA)\n",
    "n_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data_validation =N_FIT_DATA-n_data_train\n",
    "n_data_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_validation =  n_data_validation//batch_size+1\n",
    "steps_per_epoch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_validation*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING_DATASET_SIZE=200840\n",
    "#TRAINING_DATASET_SIZE =200\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "\n",
    "class SpaceNetPipeline:\n",
    "    def __init__(self, shuffle=False, batch_type='multiple_images',\n",
    "                 batch_size=BATCH_SIZE, train_val_frac = TRAIN_FRAC, \n",
    "                 backbone = 'efficientnetb3', verbose=False):\n",
    "        \n",
    "        #assert not (mode=='test' and shuffle==True), 'Error: in test mode, the values should not be shuffled.'\n",
    "\n",
    "        self.batch_size = batch_size \n",
    "        self.image_path = {'fit':TRAIN_SAR_PATH,\n",
    "                           'test':TEST_SAR_PATH}\n",
    "        self.gt_path = TRAIN_GT_PATH\n",
    "        \n",
    "        self.orientations = pd.read_csv('train/AOI_11_Rotterdam/SummaryData/SAR_orientations.txt',sep=' ', header=None)\n",
    "        self.orientations.columns = [\"image_timestamps\", \"orientation\"]\n",
    "        self.verbose = verbose\n",
    "        self.generators = {}\n",
    "        self.data_ids = {}\n",
    "        self.transforms = {}\n",
    "        self.results_polygons = {}\n",
    "        self.raw_polygons = {}\n",
    "        self.raw_predictions = {}\n",
    "        self.final_results = {}\n",
    "        \n",
    "        self.steps_per_epoch = {}\n",
    "        self.n_data = {}\n",
    "        self.n_data['train'] = int(train_val_frac*N_FIT_DATA)\n",
    "        self.n_data['validation'] = N_FIT_DATA - self.n_data['train']\n",
    "        self.n_data['test'] = len(os.listdir('test_public/AOI_11_Rotterdam/SAR-Intensity'))\n",
    "        \n",
    "        if DEBUG:\n",
    "            self.n_data['test'] = 2\n",
    "            self.n_data['train'] = 2\n",
    "            self.n_data['validation'] = 2\n",
    "        \n",
    "        for mode in ['train','validation','test']:\n",
    "            self.steps_per_epoch[mode] = self.n_data[mode]//self.batch_size\n",
    "            if self.n_data[mode]%self.batch_size != 0:\n",
    "                self.steps_per_epoch[mode]+=1\n",
    "        \n",
    "        self.image_files = {}\n",
    "        self.image_files['fit'] = os.listdir(self.image_path['fit'])\n",
    "        self.image_files['test'] = os.listdir(self.image_path['test'])\n",
    "        if shuffle == True: \n",
    "            shuffle(self.image_files['fit'])\n",
    "        self.data_ids[\"train\"] = self.image_files['fit'][:self.n_data['train']]\n",
    "        self.data_ids[\"validation\"] = self.image_files['fit'][self.n_data['train']:]\n",
    "        if batch_type == 'full_image':\n",
    "            self.generators[\"train\"] = cycle((x for x in self.image_files['fit'][:self.n_data['train']]))\n",
    "            self.generators['validation'] = cycle((x for x in self.image_files['fit'][self.n_data['train']:]))\n",
    "        elif batch_type == 'multiple_images':    \n",
    "            self.generators[\"train\"] = cycle((self.image_files['fit'][i:i+batch_size] \n",
    "                                                   for i in range(0, len(self.image_files['fit'][:self.n_data['train']]), batch_size))) \n",
    "            self.generators['validation'] = cycle((self.image_files['fit'][sn_pipeline.n_data['train']+i:sn_pipeline.n_data['train']+i+batch_size] \n",
    "                                                   for i in range(0, len(self.image_files['fit'][self.n_data['train']:]), batch_size))) \n",
    "\n",
    "        self.data_ids[\"test\"] = self.image_files['test']\n",
    "        self.generators[\"test\"] = (self.image_files['test'][i:i+batch_size] for i in range(0, len(self.image_files['fit'][:self.n_data['train']]), batch_size))\n",
    "        self.backbone = backbone\n",
    "    def print_if_verbose(self, *args, status='always'):\n",
    "        if self.verbose and status=='always':\n",
    "            print(*args)\n",
    "        if self.verbose=='debug' and status=='debug':\n",
    "            print(*args)\n",
    "\n",
    "    def normalize(self, batch, normalization_type=None):\n",
    "        if normalization_type is None:\n",
    "            normalized_batch=batch \n",
    "        elif normalization_type=='divide':\n",
    "            normalized_batch=batch/255\n",
    "        return normalized_batch\n",
    "\n",
    "    def get_xy_image(self, im_id, mode='train'):\n",
    "        if mode in ('train','validation'):\n",
    "            source = 'fit'\n",
    "        else:\n",
    "            source = 'test'\n",
    "        x_image, tsm = get_array_from_tiff(self.image_path[source]/im_id)\n",
    "        if mode in ('train','validation'):\n",
    "            y_image, tsm = get_array_from_tiff(self.gt_path/im_id)\n",
    "            y_image = y_image[0]\n",
    "        else:\n",
    "            y_image = None\n",
    "        return x_image, y_image, tsm\n",
    "\n",
    "    def process_x_batch_list(self, x_batch_list):\n",
    "        x_resized = np.ndarray(shape=(len(x_batch_list),HEIGHT,WIDTH,3))\n",
    "        for i in range(len(x_batch_list)):\n",
    "            for j in range(3):\n",
    "                x_resized[i,...,j] = cv.resize(x_batch_list[i][j],dsize=(WIDTH,HEIGHT))\n",
    "        x_batch_normalized = self.normalize(x_resized)\n",
    "        del x_batch_list\n",
    "        del x_resized\n",
    "        return x_batch_normalized\n",
    "    \n",
    "    def process_y_batch_list(self, y_batch_list):\n",
    "        y_resized = np.ndarray(shape=(len(y_batch_list),HEIGHT,WIDTH))\n",
    "        for i in range(len(y_batch_list)):\n",
    "            y_resized[i] = cv.resize(y_batch_list[i],dsize=(WIDTH,HEIGHT))\n",
    "        y_fixed_orientation = y_resized\n",
    "        y_boolean = np.uint8(y_fixed_orientation > 0)\n",
    "        y_expanded = np.expand_dims(y_boolean,axis=-1)\n",
    "        del y_batch_list\n",
    "        del y_boolean\n",
    "        del y_fixed_orientation\n",
    "        del y_resized\n",
    "        return y_expanded\n",
    "        \n",
    "    def flow(self, mode: str =\"train\", with_ground_truth = True, height: int =137,width: int =236):\n",
    "        '''Run the generator '''\n",
    "        c = 0\n",
    "        self.transforms[mode] = []\n",
    "        while True:\n",
    "            image_ids_to_get = next(self.generators[mode])\n",
    "            x_batch_list = []\n",
    "            y_batch_list = []\n",
    "            for im_id in image_ids_to_get:\n",
    "                c+=1\n",
    "                if c % 10 == 0:\n",
    "                    self.print_if_verbose(f\"\\n INFO - Step n°{c} \")\n",
    "                image_orientation = self.orientations.loc[self.orientations[\"image_timestamps\"]==re.match('.*(\\d{14}_\\d{14})',im_id)[1],\"orientation\"]\n",
    "                self.print_if_verbose(\"\\n INFO - image_ids_to_get:\", im_id,\"\\n\",status='always')\n",
    "                self.print_if_verbose(\"\\n INFO - image_orientation:\",image_orientation)\n",
    "\n",
    "                x_image, y_image, tsm = self.get_xy_image(im_id, mode)\n",
    "                self.transforms[mode].append(tsm)\n",
    "                x_batch_list.append(x_image)\n",
    "\n",
    "                if mode in ('train','validation'):\n",
    "                    self.print_if_verbose(\"\\n INFO - current mode \", mode, status=\"debug\")\n",
    "                    y_batch_list.append(y_image)\n",
    "            x_batch_processed = self.process_x_batch_list(x_batch_list)\n",
    "            \n",
    "            if mode in ('train','validation'):\n",
    "                y_batch_processed = self.process_y_batch_list(y_batch_list)\n",
    "                #self.print_if_verbose(f\"\\n INFO - Yielding train data n°{c}/{self.batch_size/self.files_size['train']}\")\n",
    "                yield x_batch_processed, y_batch_processed\n",
    "            else:\n",
    "                c+=1\n",
    "                if c % 10==0:\n",
    "                    print(f\"\\n INFO - Step n°{c} \")\n",
    "                #self.print_if_verbose(f\"\\n INFO - Yielding {mode} data n°{c}/{self.batch_size/self.files_size[mode]}\")\n",
    "                yield x_batch_processed\n",
    "            gc.collect()\n",
    "    \n",
    "    def get_callbacks(self):\n",
    "        checkpoint = ModelCheckpoint(MODELS_DIR+f\"model_weights--{self.backbone}\"+\"-{epoch:02d}-{val_loss:.4f}--{val_iou_score:.4f}.hdf5\", \n",
    "                                     monitor='val_loss', \n",
    "                                     verbose=1, \n",
    "                                     save_best_only=False, \n",
    "                                     mode='min')\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                      min_delta=0,\n",
    "                                      patience=12,\n",
    "                                      verbose=1, mode='auto')\n",
    "        csv_logger = CSVLogger(LOG_DIR+'training.log')\n",
    "\n",
    "        reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                      patience=4, min_lr=0.0001, verbose =1)\n",
    "        \n",
    "        self.callbacks = [checkpoint, early_stopping, csv_logger, reduce_lr_on_plateau]\n",
    "        #self.callbacks = []\n",
    "    \n",
    "    def get_model(self,weights_path=None):\n",
    "        self.model = sm.Unet(self.backbone, weights=weights_path)\n",
    "        self.model.compile(\n",
    "            'Adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[sm.metrics.iou_score],\n",
    "        )\n",
    "            \n",
    "    def fit(self):\n",
    "        if self.model is None: \n",
    "            raise ValueError(\"Model is not defined yet.\")\n",
    "        self.print_if_verbose(\"\\n INFO - Training...\")\n",
    "        self.history = self.model.fit_generator(\n",
    "           self.flow(mode=\"train\"),\n",
    "           epochs=N_EPOCHS,\n",
    "           steps_per_epoch=self.steps_per_epoch['train'],\n",
    "           validation_steps=self.steps_per_epoch['validation'],\n",
    "           validation_data=self.flow(mode='validation'),\n",
    "           callbacks = self.callbacks\n",
    "    )\n",
    "        \n",
    "    def get_polygons_from_predictions(self, mode, threshold = 0.5):\n",
    "        self.raw_polygons[mode] = []\n",
    "        self.final_results[mode] = []\n",
    "        n_vectorization = len(self.raw_predictions[mode])\n",
    "        t_polygons = tqdm(enumerate(self.raw_predictions[mode][...,0]),\n",
    "                          total=n_vectorization)\n",
    "        self.all_pols = []\n",
    "        aff = Affine(1,0,0,0,-1,900)\n",
    "        for i_image, pred in t_polygons:\n",
    "            t_polygons.set_description(f\"Memory: {get_resources_usage()['memory']} - CPU: {get_resources_usage()['cpu']}\")\n",
    "            if i_image == 0:\n",
    "                plt.imshow(pred)\n",
    "                plt.show()\n",
    "            if i_image==0:\n",
    "                plt.imshow(pred)\n",
    "                plt.show()\n",
    "\n",
    "            pred = cv.resize(pred,(900,900))\n",
    "            boolean_image = np.uint8(pred > threshold)\n",
    "            pols = features.shapes(boolean_image,\n",
    "                                   transform=aff\n",
    "                                  )\n",
    "            pols = [x for x in pols if x[1] ==1]\n",
    "            self.all_pols.append(pols)\n",
    "            \n",
    "            extracted = []\n",
    "            for pol,_ in  pols:\n",
    "                extracted.append(Polygon(pol['coordinates'][0]).wkt)\n",
    "            \n",
    "            extracted_values = zonal_stats(extracted,\n",
    "                                           pred,\n",
    "                                           affine = aff\n",
    "                                          )\n",
    "\n",
    "            extracted_infos = [(x,y['mean']) for x,y in zip(extracted, \n",
    "                                                            extracted_values)]\n",
    "            for pol_wkt,val in extracted_infos:\n",
    "                self.final_results[mode].append((get_id_from_filename(FILENAME_PATTERN[mode],self.data_ids[mode][i_image]), pol_wkt, val))\n",
    "            \n",
    "    def predict(self, mode='train'):\n",
    "        if self.model is None: \n",
    "            raise ValueError(\"Model is not defined yet.\")\n",
    "        with_ground_truth = True\n",
    "        \n",
    "        if mode == 'test':\n",
    "            with_ground_truth=False\n",
    "        print(\"\\n INFO - Predictions...\")\n",
    "        self.raw_predictions[mode] = self.model.predict(\n",
    "            self.flow(mode=mode,with_ground_truth=with_ground_truth),steps=self.steps_per_epoch[mode]\n",
    "        )\n",
    "        print(\"\\n INFO - Flipping predictions...\")\n",
    "        self.raw_predictions[mode] = np.flip(self.raw_predictions[mode], axis=1)\n",
    "        print(\"\\n INFO - Vectorizations...\")\n",
    "        self.get_polygons_from_predictions(mode)\n",
    "        #self.get_confidence()\n",
    "\n",
    "    def format_results(self, mode):\n",
    "        assert self.final_results[mode] is not None\n",
    "        print(\"self.final_results sample:\",self.final_results[mode][:2])\n",
    "        self.final_results[mode] = pd.DataFrame(self.final_results[mode],\n",
    "                                                columns=['ImageId','PolygonWKT_Pix','Confidence']).sort_values(by='ImageId')\n",
    "        \n",
    "    def save_results(self, mode='train'):\n",
    "        self.final_results[mode].to_csv(f'solutions/{mode}_{self.backbone}_{datetime.now().strftime(\"%Y-%m-%dT%H:%M\")}.csv', index=False)\n",
    "        \n",
    "    def run_pipeline(self, fit=True, predict_train = True, predict_validation = True, predict_test = False, weights_path=None):\n",
    "        \n",
    "        self.get_model(weights_path=weights_path)\n",
    "        \n",
    "        if fit:\n",
    "            self.get_callbacks()\n",
    "            self.fit()\n",
    "        \n",
    "        if predict_train:\n",
    "            self.print_if_verbose(\"\\n INFO - Prediction on the train set\")        \n",
    "            self.predict(mode='train')\n",
    "            self.format_results(mode='train')\n",
    "            self.save_results(mode=\"train\")\n",
    "            \n",
    "        if predict_validation:\n",
    "            self.print_if_verbose(\"\\n INFO - Prediction on the validation set\")        \n",
    "            self.predict(mode='validation')\n",
    "            self.format_results(mode='validation')\n",
    "            self.save_results(mode='validation')\n",
    "\n",
    "        if predict_test:\n",
    "            self.print_if_verbose(\"\\n INFO - Prediction on the test set\")        \n",
    "            self.predict(mode='test')\n",
    "            self.format_results(mode='test')\n",
    "            self.save_results(mode='test')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 29317940\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 20:59 model_weights--efficientnetb3-11-0.1135--0.5224.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 20:37 model_weights--efficientnetb3-10-0.1115--0.5304.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 20:14 model_weights--efficientnetb3-09-0.1250--0.5238.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 19:52 model_weights--efficientnetb3-08-0.1148--0.5307.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 19:30 model_weights--efficientnetb3-07-0.1115--0.5312.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 19:08 model_weights--efficientnetb3-06-0.1117--0.5272.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 18:45 model_weights--efficientnetb3-05-0.1196--0.5024.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 18:21 model_weights--efficientnetb3-04-0.1152--0.5321.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 18:00 model_weights--efficientnetb3-03-0.1140--0.5263.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 17:38 model_weights--efficientnetb3-02-0.1134--0.5333.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 17:17 model_weights--efficientnetb3-01-0.1198--0.5345.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 15:54 model_weights--efficientnetb3-22-0.1167--0.5421.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 15:30 model_weights--efficientnetb3-21-0.1158--0.5424.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 15:10 model_weights--efficientnetb3-20-0.1154--0.5417.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 14:48 model_weights--efficientnetb3-19-0.1137--0.5418.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 14:25 model_weights--efficientnetb3-18-0.1133--0.5416.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 14:00 model_weights--efficientnetb3-17-0.1130--0.5403.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 13:39 model_weights--efficientnetb3-16-0.1121--0.5400.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 13:18 model_weights--efficientnetb3-15-0.1113--0.5394.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 12:56 model_weights--efficientnetb3-14-0.1102--0.5354.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 12:35 model_weights--efficientnetb3-13-0.1084--0.5358.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 12:06 model_weights--efficientnetb3-12-0.1070--0.5322.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 11:44 model_weights--efficientnetb3-11-0.1044--0.5291.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 11:23 model_weights--efficientnetb3-10-0.1023--0.5261.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 11:01 model_weights--efficientnetb3-09-0.1120--0.5190.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 10:37 model_weights--efficientnetb3-08-0.1128--0.5182.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 10:16 model_weights--efficientnetb3-07-0.1111--0.5038.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 09:54 model_weights--efficientnetb3-06-0.1135--0.5028.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 09:32 model_weights--efficientnetb3-05-0.1112--0.5062.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 09:10 model_weights--efficientnetb3-04-0.1116--0.5167.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 08:49 model_weights--efficientnetb3-03-0.1158--0.5102.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 08:27 model_weights--efficientnetb3-02-0.1120--0.5081.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 28 08:05 model_weights--efficientnetb3-01-0.1188--0.5190.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 28 01:05 model_weights--efficientnetb3-08-0.1034--0.5219.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 28 00:41 model_weights--efficientnetb3-07-0.1017--0.5192.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 28 00:16 model_weights--efficientnetb3-06-0.1134--0.5216.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 23:49 model_weights--efficientnetb3-05-0.1069--0.5264.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 23:15 model_weights--efficientnetb3-04-0.1180--0.4991.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 22:46 model_weights--efficientnetb3-03-0.1216--0.4848.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 22:18 model_weights--efficientnetb3-02-0.1061--0.5104.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 27 21:44 model_weights--efficientnetb3-01-0.1127--0.5267.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 19:53 model_weights--efficientnetb3-17-0.1088--0.5251.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 19:31 model_weights--efficientnetb3-16-0.1078--0.5247.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 19:09 model_weights--efficientnetb3-15-0.1073--0.5236.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 18:44 model_weights--efficientnetb3-14-0.1069--0.5236.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 18:22 model_weights--efficientnetb3-13-0.1054--0.5231.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 17:57 model_weights--efficientnetb3-12-0.1050--0.5221.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 17:34 model_weights--efficientnetb3-11-0.1042--0.5213.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 17:12 model_weights--efficientnetb3-10-0.1039--0.5154.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 16:50 model_weights--efficientnetb3-09-0.1023--0.5130.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 16:29 model_weights--efficientnetb3-08-0.1004--0.5099.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 16:06 model_weights--efficientnetb3-07-0.0980--0.5019.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 15:44 model_weights--efficientnetb3-06-0.1108--0.5058.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 15:22 model_weights--efficientnetb3-05-0.1101--0.4844.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 15:00 model_weights--efficientnetb3-04-0.1088--0.4773.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 14:38 model_weights--efficientnetb3-03-0.1054--0.4956.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 14:17 model_weights--efficientnetb3-02-0.1134--0.4795.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 27 13:55 model_weights--efficientnetb3-01-0.1084--0.4956.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 20:28 model_weights--efficientnetb3-07-0.0638--0.5923.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 20:07 model_weights--efficientnetb3-06-0.0651--0.5915.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 19:44 model_weights--efficientnetb3-05-0.0595--0.6148.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 19:22 model_weights--efficientnetb3-04-0.0662--0.5722.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 19:01 model_weights--efficientnetb3-03-0.0629--0.5843.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 18:39 model_weights--efficientnetb3-02-0.0633--0.5986.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 18:16 model_weights--efficientnetb3-01-0.0669--0.5984.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 17:38 model_weights--efficientnetb3-03-0.0598--0.6612.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 17:38 model_weights--efficientnetb3-02-0.0657--0.6280.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 17:37 model_weights--efficientnetb3-01-0.0880--0.5940.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 14:36 model_weights-21-0.0590--0.6171.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 14:17 model_weights-20-0.0619--0.6100.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 13:57 model_weights-19-0.0545--0.6277.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 13:34 model_weights-18-0.0603--0.6031.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 13:13 model_weights-17-0.0602--0.6069.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 12:45 model_weights-16-0.0536--0.6266.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 12:18 model_weights-15-0.0622--0.5915.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 11:54 model_weights-14-0.0589--0.5990.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 11:31 model_weights-13-0.0584--0.6104.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 11:06 model_weights-12-0.0646--0.5880.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 10:46 model_weights-11-0.0596--0.5952.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 10:22 model_weights-10-0.0654--0.5717.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 10:03 model_weights-09-0.0701--0.5594.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 09:45 model_weights-08-0.0833--0.5371.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 09:23 model_weights-07-0.0773--0.5433.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 09:00 model_weights-06-0.0767--0.5570.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 08:34 model_weights-05-0.0699--0.5551.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 08:12 model_weights-04-0.0809--0.5080.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 07:51 model_weights-03-0.0768--0.5089.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 07:29 model_weights-02-0.0772--0.5333.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 26 07:03 model_weights-01-0.0857--0.4961.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 06:07 model_weights-20-0.0892--0.4897.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 05:43 model_weights-19-0.0785--0.4960.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 05:22 model_weights-18-0.0876--0.4756.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 05:02 model_weights-17-0.0892--0.4716.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 04:39 model_weights-16-0.0884--0.4694.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 04:12 model_weights-15-0.0983--0.4405.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 03:51 model_weights-14-0.0917--0.4539.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 03:30 model_weights-13-0.0926--0.4599.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 03:09 model_weights-12-0.1017--0.4415.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 02:50 model_weights-11-0.1017--0.4298.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 02:29 model_weights-10-0.1077--0.3896.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 02:10 model_weights-09-0.1152--0.3708.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 01:53 model_weights-08-0.1118--0.3681.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 01:30 model_weights-07-0.1213--0.3418.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 01:09 model_weights-06-0.1251--0.3355.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 00:45 model_weights-05-0.1281--0.3141.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 26 00:21 model_weights-04-0.1470--0.2439.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 25 23:59 model_weights-03-0.1493--0.2220.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 25 23:36 model_weights-02-0.2041--0.2033.hdf5\r\n",
      "-rw-r--r-- 1 root root 215664616 Apr 25 23:13 model_weights-01-0.4051--0.1121.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:31 model_weights-07-6.0030--0.0770.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:30 model_weights-06-5.9981--0.0576.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:30 model_weights-05-5.1046--0.0711.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:29 model_weights-04-8.3805--0.1000.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:29 model_weights-03-9.6803--0.0647.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:28 model_weights-02-3.7228--0.0196.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:27 model_weights-01-7.6915--0.0030.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:26 model_weights-06-38.7753--0.0754.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:25 model_weights-05-71.8457--0.0873.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:25 model_weights-04-135.8607--0.0705.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:25 model_weights-03-56.5476--0.0857.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:24 model_weights-02-32.3509--0.0864.hdf5\r\n",
      "-rw-r--r-- 1 root root 215666832 Apr 25 22:24 model_weights-01-29.2790--0.0948.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 12:11 model_weights-08-0.0629--0.5853.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 11:52 model_weights-07-0.0625--0.5936.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 11:37 model_weights-06-0.0621--0.5920.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 11:17 model_weights-05-0.0675--0.5583.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 11:00 model_weights-04-0.0728--0.5563.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 10:43 model_weights-03-0.0604--0.5906.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 10:24 model_weights-02-0.0674--0.5672.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357208 Apr 23 10:05 model_weights-01-0.0700--0.5894.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 16:51 model_weights-05-0.0845--0.4962.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 16:33 model_weights-04-0.0800--0.5146.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 16:15 model_weights-03-0.0821--0.5089.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 15:55 model_weights-02-0.0768--0.5158.hdf5\r\n",
      "-rw-r--r-- 1 root root 285357576 Apr 22 15:35 model_weights-01-0.0833--0.4978.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lt models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_pipeline = SpaceNetPipeline(batch_size=32, train_val_frac = TRAIN_FRAC, \n",
    "                               verbose=False, backbone = 'efficientnetb3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-01d933f5fba1>:187: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 85 steps, validate for 22 steps\n",
      "Epoch 1/40\n",
      "84/85 [============================>.] - ETA: 11s - loss: 0.0436 - iou_score: 0.6969\n",
      "Epoch 00001: saving model to models/model_weights--efficientnetb3-01-0.1226--0.5353.hdf5\n",
      "85/85 [==============================] - 1413s 17s/step - loss: 0.0438 - iou_score: 0.6968 - val_loss: 0.1226 - val_iou_score: 0.5353\n",
      "Epoch 2/40\n",
      "84/85 [============================>.] - ETA: 10s - loss: 0.0467 - iou_score: 0.6792\n",
      "Epoch 00002: saving model to models/model_weights--efficientnetb3-02-0.1126--0.5333.hdf5\n",
      "85/85 [==============================] - 1266s 15s/step - loss: 0.0469 - iou_score: 0.6793 - val_loss: 0.1126 - val_iou_score: 0.5333\n",
      "Epoch 3/40\n",
      "59/85 [===================>..........] - ETA: 5:04 - loss: 0.0465 - iou_score: 0.6815"
     ]
    }
   ],
   "source": [
    "\n",
    "sn_pipeline.run_pipeline(\n",
    "                         fit=True,\n",
    "                         predict_train = True,\n",
    "                         predict_validation = True, \n",
    "                         predict_test = True, \n",
    "                         weights_path='models/model_weights--efficientnetb3-21-0.1158--0.5424.hdf5'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sn_pipeline.data_ids['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"test\"\n",
    "sn_pipeline.final_results[mode].to_csv(f'solutions/{mode}_{sn_pipeline.backbone}_{datetime.now().strftime(\"%Y-%m-%dT%H:%M\")}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sn_pipeline.raw_predictions['test'][2,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_pipeline.data_ids['test'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sn_pipeline.transforms['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.flip(sn_pipeline.raw_predictions['train'],axis=1)[0,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sn_pipeline.raw_predictions['train'][0,...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_pipeline.raw_predictions['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_pipeline = SpaceNetPipeline(verbose=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sn_pipeline.run_pipeline(fit=False, predict_train = True, predict_validation = False, predict_test = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Méthode 1: \n",
    "- Lors de la pred, on sauve les rasters\n",
    "- On vectorise après raster par raster \n",
    "\n",
    "2) Méthode 2: \n",
    "- Pendant le training, on garde les transforme\n",
    "- Après la pred  \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train: \n",
    "java -jar visualizer.jar -image-dir /home/amiel/Projects/competitions/spacenet/spacenet6/train/AOI_11_Rotterdam/SAR-Intensity -truth /home/amiel/Projects/competitions/spacenet/spacenet6/train/AOI_11_Rotterdam/SummaryData/SN6_Train_AOI_11_Rotterdam_Buildings.csv -solution /home/amiel/Projects/competitions/spacenet/spacenet6/solutions/train_2020-04-25T16:31.csv\n",
    "#Test: \n",
    "java -jar visualizer.jar -image-dir /home/amiel/Projects/competitions/spacenet/spacenet6/test_public/AOI_11_Rotterdam/SAR-Intensity -solution /home/amiel/Projects/competitions/spacenet/spacenet6/solutions/test_2020-04-25T22:01.csv\n",
    "\n",
    "        \n",
    "        #Apparemment, pb de définition de l'image (on prédit, mais n'importe quoi )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&²# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
